{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: Using the SlimStampen Python code\n",
    "## User Models 2019/2020"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "\n",
    "This notebook contains a basic demonstration of the functionality of the provided code in `slimstampen/spacingmodel.py` to get you started.\n",
    "For more details, refer to the code itself.\n",
    "\n",
    "The provided code is compatible with Python 2.7 or newer.\n",
    "\n",
    "If you have any questions, please ask for help!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the code\n",
    "\n",
    "Download the `slimstampen` directory into your working directory.\n",
    "You can then import the SlimStampen code into your Python script as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from slimstampen.spacingmodel import SpacingModel, Fact, Response"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Note:*** If you use OpenSesame, you'll have to add the path to the `slimstampen` directory to the Python path used by OpenSesame, see https://osdoc.cogsci.nl/3.2/manual/environment/#customizing-your-environment-with-environmentyaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ### Creating a model and registering facts\n",
    "\n",
    "The `SpacingModel` object contains all the SlimStampen functionality you need to build a working system.\n",
    "\n",
    "Let's begin by creating a model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = SpacingModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now register the facts that we want our users to learn.\n",
    "\n",
    "The `Fact` class lets us define facts with a unique identifier, the question (i.e., what you show on the screen), and the answer (i.e., how you expect users to respond).\n",
    "\n",
    "Here we're creating some English-French translation facts and adding them to the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "fact1 = Fact(fact_id = 1, question = \"hello\", answer = \"bonjour\")\n",
    "fact2 = Fact(2, \"dog\", \"chien\")\n",
    "fact3 = Fact(3, \"cat\", \"chat\")\n",
    "fact4 = Fact(4, \"computer\", \"ordinateur\")\n",
    "\n",
    "m.add_fact(fact1)\n",
    "m.add_fact(fact2)\n",
    "m.add_fact(fact3)\n",
    "m.add_fact(fact4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking for the next fact to study\n",
    "\n",
    "Throughout the learning session we can repeatedly ask the model for the next fact to study.\n",
    "\n",
    "The model will return the fact that needs to be repeated most urgently at the current time (i.e., the one that is most likely to be forgotten).\n",
    "If all facts that have been studied so far are \"safe\" for now, the model returns a new fact to study instead.\n",
    "\n",
    "Along with the fact, the method also returns a boolean indicating whether the returned fact is new (`True`) or whether it has been presented before (`False`).\n",
    "We can use this information to change how the fact is presented to the user (e.g., by showing the answer when the fact has not been shown before). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Fact(fact_id=1, question='hello', answer='bonjour'), True)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_fact, new = m.get_next_fact(current_time = 34000)\n",
    "next_fact, new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging the user's response\n",
    "\n",
    "Once our system has presented the fact and obtained a response from the user, the response can be logged in the model.\n",
    "\n",
    "By using a `Response` object, we can specify to which fact the user responded, at what time the presentation of the fact started (in milliseconds since the task onset), what the response time was (in milliseconds), and whether the response was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = Response(fact = next_fact, start_time = 34029, rt = 2207, correct = True)\n",
    "\n",
    "m.register_response(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check that the response has been logged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Response(fact=Fact(fact_id=1, question='hello', answer='bonjour'), start_time=34029, rt=2207, correct=True)]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Asking for more facts\n",
    "\n",
    "When it's time to present the next trial, ask for another fact. With default parameter settings, the model chooses to immediately reinforce the fact that was just introduced, because it is likely to be forgotten otherwise. Note that this fact is now no longer marked as 'new'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Fact(fact_id=1, question='hello', answer='bonjour'), False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_fact, new = m.get_next_fact(current_time = 38000)\n",
    "next_fact, new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Behind the scenes, the `get_next_fact` method has checked the expected activation of all facts slightly in the future (by default the model looks ahead 15 seconds). Since the activation of the first fact is predicted to be lower than the threshold of -0.8, it is selected for repetition. Note that facts that have not yet been studied have an activation of $-\\infty$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Fact(fact_id=1, question='hello', answer='bonjour'), -0.8828734492111224)\n",
      "(Fact(fact_id=2, question='dog', answer='chien'), -inf)\n",
      "(Fact(fact_id=3, question='cat', answer='chat'), -inf)\n",
      "(Fact(fact_id=4, question='computer', answer='ordinateur'), -inf)\n"
     ]
    }
   ],
   "source": [
    "for f in m.facts:\n",
    "    print(f, m.calculate_activation(38000 + m.LOOKAHEAD_TIME, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say this fact is again presented to the user and a correct response is made."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = Response(fact = next_fact, start_time = 38007, rt = 1890, correct = True)\n",
    "\n",
    "m.register_response(resp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The additional successful repetition means that the activation of this fact will now still be high enough in 15 seconds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(Fact(fact_id=1, question='hello', answer='bonjour'), -0.21819151264505898)\n",
      "(Fact(fact_id=2, question='dog', answer='chien'), -inf)\n",
      "(Fact(fact_id=3, question='cat', answer='chat'), -inf)\n",
      "(Fact(fact_id=4, question='computer', answer='ordinateur'), -inf)\n"
     ]
    }
   ],
   "source": [
    "for f in m.facts:\n",
    "    print(f, m.calculate_activation(42000 + m.LOOKAHEAD_TIME, f))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sure enough, when we ask for a new fact, we get a different one:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Fact(fact_id=2, question='dog', answer='chien'), True)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_fact, new = m.get_next_fact(current_time = 42000)\n",
    "next_fact, new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estimated *rate of forgetting* ($\\alpha$)\n",
    "\n",
    "A fact's rate of forgetting ($\\alpha$) always starts at 0.3. Once at least 3 responses have been recorded, this value is adjusted up (if the fact is difficult to remember) or down (if it's easy to remember).\n",
    "\n",
    "The `get_rate_of_forgetting` method returns the estimated rate of forgetting for a fact at a specified time, given the responses that were made before that time.\n",
    "\n",
    "We can confirm that the rate of forgetting estimate for the first fact is indeed 0.3 before any responses have been logged:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "At t=0: 0.3\n"
     ]
    }
   ],
   "source": [
    "print('At t=0: {}'.format(m.get_rate_of_forgetting(0, fact1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we add some more responses for `fact1` we can see how adjustments in the estimated rate of forgetting happen (notice that adjustment only starts after response #3). In this case, the observed response times are lower than expected, so the rate of forgetting estimate is adjusted downwards to about 0.25."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After 2 responses: 0.3\n",
      "After 3 responses: 0.250390625\n",
      "After 4 responses: 0.25625\n",
      "After 5 responses: 0.244140625\n"
     ]
    }
   ],
   "source": [
    "print('After 2 responses: {}'.format(m.get_rate_of_forgetting(50000, fact1)))\n",
    "\n",
    "resp = Response(fact = fact1, start_time = 50000, rt = 1200, correct = True)\n",
    "m.register_response(resp)\n",
    "\n",
    "print('After 3 responses: {}'.format(m.get_rate_of_forgetting(60000, fact1)))\n",
    "\n",
    "resp = Response(fact = fact1, start_time = 60000, rt = 1100, correct = True)\n",
    "m.register_response(resp)\n",
    "\n",
    "print('After 4 responses: {}'.format(m.get_rate_of_forgetting(70000, fact1)))\n",
    "\n",
    "resp = Response(fact = fact1, start_time = 70000, rt = 900, correct = True)\n",
    "m.register_response(resp)\n",
    "\n",
    "print('After 5 responses: {}'.format(m.get_rate_of_forgetting(80000, fact1)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting the response data\n",
    "\n",
    "The method `export_data` provides a simple way of saving the response data and the model estimates. It also returns a copy of the data in case you want to do more with it.\n",
    "\n",
    "The column `alpha` contains the estimated rate of forgetting *after* the trial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>start_time</th>\n",
       "      <th>rt</th>\n",
       "      <th>correct</th>\n",
       "      <th>fact_id</th>\n",
       "      <th>question</th>\n",
       "      <th>answer</th>\n",
       "      <th>alpha</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>trial</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>34029</td>\n",
       "      <td>2207</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>hello</td>\n",
       "      <td>bonjour</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>38007</td>\n",
       "      <td>1890</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>hello</td>\n",
       "      <td>bonjour</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50000</td>\n",
       "      <td>1200</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>hello</td>\n",
       "      <td>bonjour</td>\n",
       "      <td>0.250391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>60000</td>\n",
       "      <td>1100</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>hello</td>\n",
       "      <td>bonjour</td>\n",
       "      <td>0.256250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>70000</td>\n",
       "      <td>900</td>\n",
       "      <td>True</td>\n",
       "      <td>1</td>\n",
       "      <td>hello</td>\n",
       "      <td>bonjour</td>\n",
       "      <td>0.244141</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       start_time    rt  correct  fact_id question   answer     alpha\n",
       "trial                                                                \n",
       "1           34029  2207     True        1    hello  bonjour  0.300000\n",
       "2           38007  1890     True        1    hello  bonjour  0.300000\n",
       "3           50000  1200     True        1    hello  bonjour  0.250391\n",
       "4           60000  1100     True        1    hello  bonjour  0.256250\n",
       "5           70000   900     True        1    hello  bonjour  0.244141"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.export_data(\"data.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
